{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest kobe bryant\n",
    "\n",
    "This project is inspired by Siraj Raval's [Video](https://www.youtube.com/watch?v=QHOazyP-YlM) and [notebook](https://github.com/llSourcell/random_forests/blob/master/Random%20Forests%20.ipynb) about random forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gini index\n",
    "\n",
    "The gini index calculates a score for a split, that was done on the data. That score gives an idea how mixed the resulting groups are. If instances of only one category are in the group, the gini index is zero.\n",
    "\n",
    "The gini index of one group is calculated like this:\n",
    "\n",
    "```python\n",
    "gini = 1\n",
    "for c in classes:\n",
    "    count = group['class'].count(c)\n",
    "    gini -= (count * count) / (len(group) * len(group))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_type</th>\n",
       "      <th>combined_shot_type</th>\n",
       "      <th>game_event_id</th>\n",
       "      <th>game_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>loc_x</th>\n",
       "      <th>loc_y</th>\n",
       "      <th>lon</th>\n",
       "      <th>minutes_remaining</th>\n",
       "      <th>period</th>\n",
       "      <th>...</th>\n",
       "      <th>class</th>\n",
       "      <th>shot_type</th>\n",
       "      <th>shot_zone_area</th>\n",
       "      <th>shot_zone_basic</th>\n",
       "      <th>shot_zone_range</th>\n",
       "      <th>team_id</th>\n",
       "      <th>team_name</th>\n",
       "      <th>game_date</th>\n",
       "      <th>matchup</th>\n",
       "      <th>opponent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jump Shot</td>\n",
       "      <td>Jump Shot</td>\n",
       "      <td>12</td>\n",
       "      <td>20000012</td>\n",
       "      <td>34.0443</td>\n",
       "      <td>-157</td>\n",
       "      <td>0</td>\n",
       "      <td>-118.4268</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2PT Field Goal</td>\n",
       "      <td>Left Side(L)</td>\n",
       "      <td>Mid-Range</td>\n",
       "      <td>8-16 ft.</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>LAL @ POR</td>\n",
       "      <td>POR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jump Shot</td>\n",
       "      <td>Jump Shot</td>\n",
       "      <td>35</td>\n",
       "      <td>20000012</td>\n",
       "      <td>33.9093</td>\n",
       "      <td>-101</td>\n",
       "      <td>135</td>\n",
       "      <td>-118.3708</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2PT Field Goal</td>\n",
       "      <td>Left Side Center(LC)</td>\n",
       "      <td>Mid-Range</td>\n",
       "      <td>16-24 ft.</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>LAL @ POR</td>\n",
       "      <td>POR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jump Shot</td>\n",
       "      <td>Jump Shot</td>\n",
       "      <td>43</td>\n",
       "      <td>20000012</td>\n",
       "      <td>33.8693</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>-118.1318</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2PT Field Goal</td>\n",
       "      <td>Right Side Center(RC)</td>\n",
       "      <td>Mid-Range</td>\n",
       "      <td>16-24 ft.</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>LAL @ POR</td>\n",
       "      <td>POR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Driving Dunk Shot</td>\n",
       "      <td>Dunk</td>\n",
       "      <td>155</td>\n",
       "      <td>20000012</td>\n",
       "      <td>34.0443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-118.2698</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2PT Field Goal</td>\n",
       "      <td>Center(C)</td>\n",
       "      <td>Restricted Area</td>\n",
       "      <td>Less Than 8 ft.</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>LAL @ POR</td>\n",
       "      <td>POR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jump Shot</td>\n",
       "      <td>Jump Shot</td>\n",
       "      <td>244</td>\n",
       "      <td>20000012</td>\n",
       "      <td>34.0553</td>\n",
       "      <td>-145</td>\n",
       "      <td>-11</td>\n",
       "      <td>-118.4148</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2PT Field Goal</td>\n",
       "      <td>Left Side(L)</td>\n",
       "      <td>Mid-Range</td>\n",
       "      <td>8-16 ft.</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>2000-10-31</td>\n",
       "      <td>LAL @ POR</td>\n",
       "      <td>POR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         action_type combined_shot_type  game_event_id   game_id      lat  \\\n",
       "1          Jump Shot          Jump Shot             12  20000012  34.0443   \n",
       "2          Jump Shot          Jump Shot             35  20000012  33.9093   \n",
       "3          Jump Shot          Jump Shot             43  20000012  33.8693   \n",
       "4  Driving Dunk Shot               Dunk            155  20000012  34.0443   \n",
       "5          Jump Shot          Jump Shot            244  20000012  34.0553   \n",
       "\n",
       "   loc_x  loc_y       lon  minutes_remaining  period  ...  class  \\\n",
       "1   -157      0 -118.4268                 10       1  ...    0.0   \n",
       "2   -101    135 -118.3708                  7       1  ...    1.0   \n",
       "3    138    175 -118.1318                  6       1  ...    0.0   \n",
       "4      0      0 -118.2698                  6       2  ...    1.0   \n",
       "5   -145    -11 -118.4148                  9       3  ...    0.0   \n",
       "\n",
       "        shot_type         shot_zone_area  shot_zone_basic  shot_zone_range  \\\n",
       "1  2PT Field Goal           Left Side(L)        Mid-Range         8-16 ft.   \n",
       "2  2PT Field Goal   Left Side Center(LC)        Mid-Range        16-24 ft.   \n",
       "3  2PT Field Goal  Right Side Center(RC)        Mid-Range        16-24 ft.   \n",
       "4  2PT Field Goal              Center(C)  Restricted Area  Less Than 8 ft.   \n",
       "5  2PT Field Goal           Left Side(L)        Mid-Range         8-16 ft.   \n",
       "\n",
       "      team_id           team_name   game_date    matchup  opponent  \n",
       "1  1610612747  Los Angeles Lakers  2000-10-31  LAL @ POR       POR  \n",
       "2  1610612747  Los Angeles Lakers  2000-10-31  LAL @ POR       POR  \n",
       "3  1610612747  Los Angeles Lakers  2000-10-31  LAL @ POR       POR  \n",
       "4  1610612747  Los Angeles Lakers  2000-10-31  LAL @ POR       POR  \n",
       "5  1610612747  Los Angeles Lakers  2000-10-31  LAL @ POR       POR  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's only take the data which is labeled\n",
    "data = data[pd.notna(data['shot_made_flag'])]\n",
    "data.rename(columns={'shot_made_flag': 'class'},\n",
    "            inplace=True)\n",
    "data.drop('shot_id', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important global dict for distinguishing categorical and numerical columns\n",
    "feature_type = {'action_type': 'cat',\n",
    "                'combined_shot_type': 'cat',\n",
    "                'game_event_id': 'num',\n",
    "                'game_id': 'num',\n",
    "                'lat': 'num',\n",
    "                'loc_x': 'num',\n",
    "                'loc_y': 'num',\n",
    "                'lon': 'num',\n",
    "                'minutes_remaining': 'num',\n",
    "                'period': 'cat',\n",
    "                'playoffs': 'cat',\n",
    "                'season': 'cat',\n",
    "                'seconds_remaining': 'num',\n",
    "                'shot_distance': 'num',\n",
    "                'shot_type': 'cat',\n",
    "                'shot_zone_area': 'cat',\n",
    "                'shot_zone_range': 'cat',\n",
    "                'shot_zone_basic': 'cat',\n",
    "                'team_id': 'cat',\n",
    "                'team_name': 'cat',\n",
    "                'game_date': 'cat',\n",
    "                'matchup': 'cat',\n",
    "                'opponent': 'cat',}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample(df, sample_size, return_indexes=False):\n",
    "    \"\"\"\n",
    "    returns a random subsample of the dataframe with size sample_size\n",
    "    df: pd.DataFrame\n",
    "    sample_size: integer\n",
    "    return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    indexes = np.random.choice(df.index, sample_size)\n",
    "    if return_indexes:\n",
    "        return df.loc[indexes], indexes\n",
    "    else:\n",
    "        return df.loc[indexes]\n",
    "\n",
    "def cross_validation_split(df, n_folds):\n",
    "    \"\"\"\n",
    "    returns n_folds dataframes out of df with equal length\n",
    "    df: pd.DataFrame\n",
    "    n_folds: integer\n",
    "    return: list of pd.DataFrame\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    fold_size = int(len(df) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold, indexes = subsample(df, fold_size, return_indexes=True)\n",
    "        dfs.append(fold)\n",
    "        df.drop(indexes, inplace=True)\n",
    "    return dfs\n",
    "\n",
    "def split_by(df, feature, value, is_numerical=True):\n",
    "    \"\"\"\n",
    "    make the split of a decision tree node\n",
    "    df: pd.DataFrame\n",
    "    feature: column name (mostly string)\n",
    "    value: any\n",
    "    is_numerical: bool\n",
    "    return: (pd.DataFrame, pd.DataFrame)\n",
    "    \"\"\"\n",
    "    if is_numerical:\n",
    "        return df[df[feature] < value], df[df[feature] >= value]\n",
    "    else:\n",
    "        # categorical feature\n",
    "        return df[df[feature] == value], df[df[feature] != value]\n",
    "        \n",
    "def accuracy(predicted, target):\n",
    "    \"\"\"\n",
    "    return percentage of correctly predicted cases\n",
    "    predicted: np.array\n",
    "    target: np.array\n",
    "    return: float between 0 and 1\n",
    "    \"\"\"\n",
    "    assert len(predicted) == len(target)\n",
    "    return (predicted == target).sum() / len(predicted)\n",
    "\n",
    "def most_frequent(array):\n",
    "    \"\"\"\n",
    "    return value that is the most frequent\n",
    "    array: np.array\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(array, return_counts=True)\n",
    "    return unique[np.argmax(counts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(splits, info=False):\n",
    "    \"\"\"\n",
    "    calculate weighted gini index of splits\n",
    "    splits: list of pd.DataFrame (normally of length 2)\n",
    "    info: bool (if True, print)\n",
    "    \"\"\"\n",
    "    overall_gini = 0\n",
    "    len_sum = sum([len(s) for s in splits])\n",
    "    for df in splits:\n",
    "        if info:\n",
    "            print(f'len: {len(df)}')\n",
    "        gini = 1\n",
    "        l = len(df)\n",
    "        for c in np.unique(df['class'].to_numpy()):\n",
    "            count = (df['class'] == c).sum()\n",
    "            gini -= (count * count) / (l*l)\n",
    "            if info:\n",
    "                print(f'c: {c}, count: {count}')\n",
    "        if info:\n",
    "            print(f'gini: {gini}')\n",
    "        overall_gini += gini * (len(df)/len_sum)\n",
    "    return overall_gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOP Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    This class is the Class which builds the Tree,\n",
    "    In the init function it searches the best split \n",
    "    possible for the given (branch) of data by using\n",
    "    the gini index, if the depth isn't at the maximum\n",
    "    yet, it builds it's childs\n",
    "    attributes:\n",
    "    feat: string\n",
    "    value: any\n",
    "    num: bool\n",
    "    left: Node or class\n",
    "    right: Node or class\n",
    "    \"\"\"\n",
    "    def __init__(self, data, depth, max_depth, min_size, info=False):\n",
    "        \"\"\"\n",
    "        find best possible split for the data\n",
    "        data: pd.DataFrame\n",
    "        depth: integer\n",
    "        max_depth: integer\n",
    "        min_size: integer\n",
    "        info: bool (if True print info)\n",
    "        \"\"\"\n",
    "        if info:\n",
    "            print(f'===== Node depth: {depth}, datalength: {len(data)} =====')\n",
    "        best = None\n",
    "        # find best split\n",
    "        feature_values = {}\n",
    "        for i, (ind, row) in enumerate(data.iterrows()):\n",
    "            if info and i % 100 == 0:\n",
    "                print(f'{i}th row')\n",
    "            for feat in data.columns:\n",
    "                if feat == 'class':\n",
    "                    # this is not a feature, it's the class\n",
    "                    continue\n",
    "                num = feature_type[feat] == 'num'\n",
    "                val = row[feat]\n",
    "                if not num and not feature_values.get(feat, None):\n",
    "                    feature_values[feat] = []\n",
    "                # test split only once for every value of a categorical feature\n",
    "                if not num and val not in feature_values[feat]:\n",
    "                    feature_values[feat].append(val)\n",
    "                elif not num:\n",
    "                    continue\n",
    "                    \n",
    "                # do the split by the test\n",
    "                # split_by(data, feature, value, is_numerical)\n",
    "                left, right = split_by(data, feat, val, num)\n",
    "                if len(left) == 0 or len(right) == 0:\n",
    "                    if not best: # prevent having no split at all:\n",
    "                        best = {\n",
    "                            'gini': 1.0,\n",
    "                            'feature': feat,\n",
    "                            'value': val,\n",
    "                            'left': left,\n",
    "                            'right': right\n",
    "                        }\n",
    "                    continue # don't make splits with no split\n",
    "                # calculate score of this split\n",
    "                gini = gini_index([left, right])\n",
    "                if not best or gini < best['gini']:\n",
    "                    best = {\n",
    "                        'gini': gini,\n",
    "                        'feature': feat,\n",
    "                        'value': val,\n",
    "                        'left': left,\n",
    "                        'right': right\n",
    "                    }\n",
    "                    if info:\n",
    "                        print(f'gini: {gini}, test: {feat} {\"<\" if num else \"==\"} {val}')\n",
    "                    \n",
    "        self.feat = best['feature']\n",
    "        self.value = best['value']\n",
    "        self.num = feature_type[self.feat] == 'num'\n",
    "        left, right = best['left'], best['right']\n",
    "        \n",
    "        # edge cases\n",
    "        if left.empty or right.empty:\n",
    "            class_array = np.concatenate([left['class'].to_numpy(), right['class'].to_numpy()])\n",
    "            self.left = self.right = most_frequent(class_array)\n",
    "        elif depth >= max_depth:\n",
    "            self.left = most_frequent(left['class'].to_numpy())\n",
    "            self.right = most_frequent(right['class'].to_numpy())\n",
    "        else:\n",
    "            if len(left) <= min_size:\n",
    "                self.left = most_frequent(left['class'].to_numpy())\n",
    "            else:\n",
    "                # child node left\n",
    "                self.left = Node(left, depth+1, max_depth, min_size, info=info)\n",
    "            if len(right) <= min_size:\n",
    "                self.right = most_frequent(right['class'].to_numpy())\n",
    "            else:\n",
    "                self.right = Node(right, depth+1, max_depth, min_size, info=info)           \n",
    "        \n",
    "    def predict(self, row):\n",
    "        \"\"\"\n",
    "        check row on my split, \n",
    "        then send it to child node,\n",
    "        or return class if no child\n",
    "        row: pd.Series / pd.DataFrame\n",
    "        \"\"\"\n",
    "        if isinstance(row, pd.Series):\n",
    "            if (self.num and row[self.feat] < self.value) or (not self.num and row[self.feat] == self.value):\n",
    "                # left is for those with smaller value if numerical\n",
    "                # or for those with equal category in feature if categorical\n",
    "                if isinstance(self.left, Node):\n",
    "                    return self.left.predict(row)\n",
    "                else:\n",
    "                    return self.left\n",
    "            else:\n",
    "                if isinstance(self.right, Node):\n",
    "                    return self.right.predict(row)\n",
    "                else:\n",
    "                    return self.right\n",
    "        elif isinstance(row, pd.DataFrame):\n",
    "            predictions = np.array([])\n",
    "            left_rows = row[row[self.feat] < self.value] if self.num else row[row[self.feat] == self.value]\n",
    "            if isinstance(self.left, Node):\n",
    "                predictions = np.append(predictions, self.left.predict(left_rows), axis=0)\n",
    "            else:\n",
    "                predictions = np.append(predictions, np.full((len(left_rows)), self.left), axis=0)\n",
    "                              \n",
    "            right_rows = row[row[self.feat] >= self.value] if self.num else row[row[self.feat] != self.value]\n",
    "            if isinstance(self.right, Node):\n",
    "                predictions = np.append(predictions, self.right.predict(right_rows), axis=0)\n",
    "            else:\n",
    "                predictions = np.append(predictions, np.full((len(right_rows)), self.right), axis=0)\n",
    "            \n",
    "            return predictions\n",
    "                              \n",
    "    def __str__(self):\n",
    "        return f'{self.feat} {\"<\" if self.num else \"==\"} {self.value}'\n",
    "\n",
    "    def show(self):\n",
    "        \"\"\"\n",
    "        prints out the structure of the tree\n",
    "        \"\"\"\n",
    "        # make dict of key being a level of height in the print \n",
    "        # and the value being a tuple of string and int, with being the depth\n",
    "        index = {0: str(self)}\n",
    "        current = [(self, 0)]\n",
    "        next_ = []\n",
    "        depth = 0\n",
    "        while len(current):\n",
    "            depth += 1\n",
    "            strs = []\n",
    "            for node, lvl in current:\n",
    "                if isinstance(node, Node):\n",
    "                    index[lvl] = (str(node), depth)\n",
    "                    step = 2**depth\n",
    "                    next_.append((node.left, lvl + 1 / step))\n",
    "                    next_.append((node.right, lvl - 1 / step))\n",
    "                else:\n",
    "                    index[lvl] = (f'class: {node}', depth)\n",
    "            current = next_\n",
    "            next_ = []\n",
    "        \n",
    "        for lvl in sorted(index.keys()):\n",
    "            s, depth = index[lvl]\n",
    "            # twelve is max length of \n",
    "            print(f'{(8 * (depth-1)) * \" \"}{s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    \"\"\"\n",
    "    random forest of certain number of nodes (tree roots)\n",
    "    which are decision trees built out of random subsample\n",
    "    of data\n",
    "    \"\"\"\n",
    "    def __init__(self, train, n_trees, max_depth, min_node_size, sample_size, info=False, node_info=False):\n",
    "        \"\"\"\n",
    "        create n_trees roots (trees)\n",
    "        train: pd.DataFrame\n",
    "        n_trees: integer\n",
    "        max_depth: integers\n",
    "        \"\"\"\n",
    "        self.trees = []\n",
    "        for i in range(n_trees):\n",
    "            if info:\n",
    "                print(f'{i}th tree')\n",
    "            self.trees.append(Node(subsample(train, sample_size), 1, max_depth, min_node_size, info=node_info))\n",
    "        \n",
    "    def predict(self, row, return_all=False):\n",
    "        predictions = np.array([tree.predict(row) for tree in self.trees])\n",
    "        if isinstance(row, pd.Series):\n",
    "            if return_all:\n",
    "                return most_frequent(predictions), predictions\n",
    "            else:\n",
    "                return most_frequent(predictions)\n",
    "        elif isinstance(row, pd.DataFrame):\n",
    "            # row i are all predictions of tree i\n",
    "            # column i are all predictions for the ith row in the df (named row)\n",
    "            predictions = np.array([tree.predict(row) for tree in self.trees])\n",
    "            # np.array of the prediction for every row in the df (named row)\n",
    "            results = np.array([most_frequent(predictions[:, i]) for i in range(len(predictions[0]))])\n",
    "            if return_all:\n",
    "                return results, predictions\n",
    "            else:\n",
    "                return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th tree\n",
      "1th tree\n",
      "2th tree\n",
      "3th tree\n",
      "4th tree\n",
      "5th tree\n",
      "6th tree\n",
      "7th tree\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-3537830b6035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-172-03f8715811c9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, train, n_trees, max_depth, min_node_size, sample_size, info, node_info)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{i}th tree'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_node_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-160-86055b01a772>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, depth, max_depth, min_size, info)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;31m# child node left\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmost_frequent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-160-86055b01a772>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, depth, max_depth, min_size, info)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;31m# do the split by the test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# split_by(data, feature, value, is_numerical)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# prevent having no split at all:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ef4e94f0a117>\u001b[0m in \u001b[0;36msplit_by\u001b[0;34m(df, feature, value, is_numerical)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \"\"\"\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_numerical\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# categorical feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2916\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2920\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2967\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, is_copy)\u001b[0m\n\u001b[1;32m   3357\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   3358\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3359\u001b[0;31m                                    verify=True)\n\u001b[0m\u001b[1;32m   3360\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 1350\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   1234\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 1235\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   1234\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 1235\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1236\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[0;32m-> 1238\u001b[0;31m                                        allow_fill=True, fill_value=fill_value)\n\u001b[0m\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n\u001b[0;32m-> 1654\u001b[0;31m                                  mask_info=mask_info)\n\u001b[0m\u001b[1;32m   1655\u001b[0m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_get_take_nd_function\u001b[0;34m(ndim, arr_dtype, out_dtype, axis, mask_info)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_take_nd_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1419\u001b[0;31m         \u001b[0mtup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marr_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_take_1d_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m_name_get\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;31m# append bit counts to str, unicode, and void\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflexible\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_isunsized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda3/lib/python3.7/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0marg2_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0marg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folds = cross_validation_split(data, 10)\n",
    "train = pd.concat(folds[:-1])\n",
    "\n",
    "forest = RandomForest(train, 10, 10, 1, 5000, info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = forest.predict(test)\n",
    "accuracy(p, test['class'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
